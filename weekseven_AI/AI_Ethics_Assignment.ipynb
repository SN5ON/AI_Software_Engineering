{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Part 1: Theoretical Understanding (30%)\n",
        "1. Short Answer Questions\n",
        "\n",
        "    Q1: Define algorithmic bias and provide two examples of how it manifests in AI systems.\n",
        "\n",
        "Algorithmic bias refers to systematic and repeatable errors in an AI system that lead to unfair outcomes, often disadvantaging certain individuals or groups. Bias can emerge from training data, model design, or real world deployment contexts. Example 1 – Biased Job Screening:\n",
        "Amazon’s hiring algorithm penalized resumes that included the word “women’s” (e.g., “women’s chess club”) because it was trained on data from predominantly male applicants, reinforcing gender bias.\n",
        "\n",
        "Example 2 – Credit Scoring Disparities:\n",
        "Some AI based credit scoring systems have reduced loan approvals for minority applicants due to biased historical lending data, even when applicants had similar financial profiles to others.\n",
        "\n",
        "\n",
        "    Q2: Explain the difference between transparency and explainability in AI. Why are both important?\n",
        "\n",
        "\n",
        "Transparency refers to how open and accessible an AI system’s components and operations are. It involves disclosing model architecture, training data sources, and decision logic.\n",
        "\n",
        "Explainability refers to the ability to understand why and how a specific AI decision was made. This is crucial for building trust and accountability, especially in high-stakes decisions like healthcare or justice.\n",
        "\n",
        "    Why  it is  Important:\n",
        "Transparency helps identify and correct systemic issues in AI systems, while explainability empowers users, regulators, and impacted individuals to interpret and challenge decisions — reducing risks of harm and enhancing fairness.\n",
        "\n",
        "    Q3: How does GDPR (General Data Protection Regulation) impact AI development in the EU?\n",
        "\n",
        "GDPR mandates data privacy, accountability, and transparency in data processing, directly impacting AI systems that rely on personal data.\n",
        "\n",
        "Key effects:\n",
        "\n",
        "Right to Explanation: Individuals can request explanations for algorithmic decisions (Article 22).\n",
        "\n",
        "Consent: AI systems must obtain informed and explicit consent before processing personal data.\n",
        "\n",
        "Data Minimization: Only data necessary for a specific purpose can be collected and used.\n",
        "\n",
        "This pushes developers to adopt privacy-preserving and human-centric AI practices, ensuring compliance while safeguarding user rights.\n",
        "\n",
        "\n",
        "\n",
        "      2. Ethical Principles Matching\n",
        "\n",
        "Match the following principles to their definitions:\n",
        "\n",
        "A) Justice\n",
        "\n",
        "B) Non-maleficence\n",
        "\n",
        "C) Autonomy\n",
        "\n",
        "    D) Sustainability:\n",
        "\n",
        "1) Ensuring AI does not harm individuals or society.\n",
        "\n",
        "2) Respecting users’ right to control their data and decisions.\n",
        "\n",
        "3) Designing AI to be environmentally friendly.\n",
        "\n",
        "4) Fair distribution of AI benefits and risks.\n",
        "\n",
        "\n",
        "| Principle          | Definition                                                   |\n",
        "| ------------------ | ------------------------------------------------------------ |\n",
        "| A) Justice         | Fair distribution of AI benefits and risks.                  |\n",
        "| B) Non-maleficence | Ensuring AI does not harm individuals or society.            |\n",
        "| C) Autonomy        | Respecting users’ right to control their data and decisions. |\n",
        "| D) Sustainability  | Designing AI to be environmentally friendly.                 |\n",
        "\n",
        "\n",
        "\n",
        "    Part 2: Case Study Analysis (40%)\n",
        "    Case 1: Biased Hiring Tool\n",
        "\n",
        "    Scenario: Amazon’s AI recruiting tool penalized female candidates.\n",
        "\n",
        "Tasks:\n",
        "\n",
        "Identify the source of bias (e.g., training data, model design).\n",
        "\n",
        "Propose three fixes to make the tool fairer.\n",
        "\n",
        "Suggest metrics to evaluate fairness post-correction.\n",
        "\n",
        "\n",
        "      1. Source of Bias\n",
        "Training Data Bias:\n",
        "\n",
        "The model was trained on past hiring data where male candidates were overrepresented, leading it to learn that male-associated patterns were more desirable.\n",
        "\n",
        "Model Design Flaws:\n",
        "\n",
        "The system lacked a fairness check and feature sensitivity review. it treated certain gender related terms as negative indicators.\n",
        "\n",
        "Unbalanced Labeling:\n",
        "\n",
        "Past hiring decisions encoded implicit gender bias, which the AI then replicated.\n",
        "\n",
        "\n",
        "    2. Three Fixes to Make the Tool Fairer\n",
        "Debias Training Data\n",
        "\n",
        "Use techniques like reweighting or resampling to reduce overrepresentation of male dominated examples. Remove biased labels or adjust them with domain experts.\n",
        "\n",
        "Feature Scrubbing & Fairness Constraints\n",
        "\n",
        "Eliminate gender proxies (e.g., college women’s clubs, first names) from input features.\n",
        "\n",
        "Apply fairness aware algorithms that enforce demographic parity or equal opportunity.\n",
        "\n",
        "Fairness Audits & Human Review\n",
        "\n",
        "Regularly run audits using tools like AI Fairness 360.\n",
        "\n",
        "Integrate human reviewers at checkpoints, especially for sensitive roles.\n",
        "\n",
        "\n",
        "\n",
        "    3. Fairness Metrics to Use Post-Correction\n",
        "Disparate Impact Ratio\n",
        "\n",
        "Measures whether outcomes differ between groups (ideal is near 1.0).\n",
        "\n",
        "Equal Opportunity Difference\n",
        "\n",
        "Compares true positive rates across groups to ensure fairness in opportunity.\n",
        "\n",
        "False Positive Rate Parity\n",
        "\n",
        "Ensures misclassifications don’t disproportionately affect one gender group.\n",
        "\n",
        "    Case 2: Facial Recognition in Policing\n",
        "\n",
        "    Scenario: A facial recognition system misidentifies minorities at higher rates.\n",
        "\n",
        "Tasks:\n",
        "\n",
        "1) Discuss ethical risks (e.g., wrongful arrests, privacy violations).\n",
        "\n",
        "2) Recommend policies for responsible deployment.\n",
        "\n",
        "    1. Ethical Risks\n",
        "Wrongful Arrests and Legal Harm\n",
        "\n",
        "A misidentified person may be jailed or fined unjustly, violating due process.\n",
        "\n",
        "Mass Surveillance\n",
        "\n",
        "Use of facial recognition without consent or oversight violates privacy rights.\n",
        "\n",
        "Algorithmic Discrimination\n",
        "\n",
        "Marginalized groups bear the burden of technical inaccuracies, reinforcing systemic biases.\n",
        "\n",
        "    2. Policy Recommendations for Responsible Deployment\n",
        "Independent Auditing Before Use\n",
        "\n",
        "\n",
        "Require vendors to provide transparency into training datasets and performance breakdowns across race, age, and gender.\n",
        "\n",
        "Human Oversight Mandate\n",
        "\n",
        "Facial recognition results should never be used as sole evidence. Decisions must be verified by trained human personnel.\n",
        "\n",
        "Strict Deployment Boundaries\n",
        "\n",
        "Restrict use in public spaces unless with a warrant or extreme necessity.\n",
        "\n",
        "Ban real-time mass surveillance (as some EU cities have done).\n",
        "\n",
        "Consent and Transparency Policies\n",
        "\n",
        "Communities should be informed when and where the technology is deployed. Opt-out mechanisms should be explored.\n",
        "\n",
        "\n",
        "    Part 3: Practical Audit (25%)\n",
        "    Task: Audit a Dataset for Bias\n",
        "\n",
        "    Dataset: COMPAS Recidivism Dataset.\n",
        "\n",
        "    Goal:\n",
        "\n",
        "    Use Python and AI Fairness 360 (IBM’s toolkit) to analyze racial bias in risk scores.\n",
        "\n",
        "    Generate visualizations (e.g., disparity in false positive rates).\n",
        "\n",
        "    Write a 300-word report summarizing findings and remediation steps.\n",
        "\n",
        "    Deliverable: Code + report.\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "sMu4ypzvS0uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aif360\n",
        "!pip install -q 'aif360[all]'  # Optional: for extra datasets and metrics\n",
        "!pip install fairlearn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL3-gMlhbvfu",
        "outputId": "b881464a-4435-4001-d735-663f693ff6b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aif360\n",
            "  Downloading aif360-0.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.11/dist-packages (from aif360) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from aif360) (1.15.3)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from aif360) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from aif360) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from aif360) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->aif360) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->aif360) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->aif360) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->aif360) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->aif360) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360) (1.17.0)\n",
            "Downloading aif360-0.6.1-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.7/259.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aif360\n",
            "Successfully installed aif360-0.6.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.7/515.7 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.6/244.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.4/69.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fairlearn in /usr/local/lib/python3.11/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.15.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from aif360.datasets import CompasDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p08lMj-LUsat",
        "outputId": "fd8f824c-b6b9-40e8-9171-8e09a7b6b612"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
            "  vect_normalized_discounted_cumulative_gain = vmap(\n",
            "/usr/local/lib/python3.11/dist-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
            "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data/compas\n",
        "!wget https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv -O data/compas/compas-scores-two-years.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1wT_xt2XYeY",
        "outputId": "d2c44c9f-29c1-4017-a708-25b743464799"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-21 09:43:10--  https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2546489 (2.4M) [text/plain]\n",
            "Saving to: ‘data/compas/compas-scores-two-years.csv’\n",
            "\n",
            "data/compas/compas- 100%[===================>]   2.43M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-07-21 09:43:10 (32.6 MB/s) - ‘data/compas/compas-scores-two-years.csv’ saved [2546489/2546489]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"data/compas/compas-scores-two-years.csv\")\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "taaC561zXbG-",
        "outputId": "098349ea-66b7-4a0e-bb62-3f028a6a331f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                name   first         last compas_screening_date   sex  \\\n",
              "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
              "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
              "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
              "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
              "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
              "\n",
              "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
              "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
              "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
              "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
              "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
              "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
              "\n",
              "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
              "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
              "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
              "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
              "3        Medium        2013-01-13         NaN          NaN               1   \n",
              "4           Low        2013-03-26         NaN          NaN               2   \n",
              "\n",
              "  start   end event two_year_recid  \n",
              "0     0   327     0              0  \n",
              "1     9   159     1              1  \n",
              "2     0    63     0              1  \n",
              "3     0  1174     0              0  \n",
              "4     0  1102     0              0  \n",
              "\n",
              "[5 rows x 53 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-edfd811e-1629-4546-b2c4-7d4e29eb96e0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>first</th>\n",
              "      <th>last</th>\n",
              "      <th>compas_screening_date</th>\n",
              "      <th>sex</th>\n",
              "      <th>dob</th>\n",
              "      <th>age</th>\n",
              "      <th>age_cat</th>\n",
              "      <th>race</th>\n",
              "      <th>...</th>\n",
              "      <th>v_decile_score</th>\n",
              "      <th>v_score_text</th>\n",
              "      <th>v_screening_date</th>\n",
              "      <th>in_custody</th>\n",
              "      <th>out_custody</th>\n",
              "      <th>priors_count.1</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>event</th>\n",
              "      <th>two_year_recid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>miguel hernandez</td>\n",
              "      <td>miguel</td>\n",
              "      <td>hernandez</td>\n",
              "      <td>2013-08-14</td>\n",
              "      <td>Male</td>\n",
              "      <td>1947-04-18</td>\n",
              "      <td>69</td>\n",
              "      <td>Greater than 45</td>\n",
              "      <td>Other</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-08-14</td>\n",
              "      <td>2014-07-07</td>\n",
              "      <td>2014-07-14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>327</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>kevon dixon</td>\n",
              "      <td>kevon</td>\n",
              "      <td>dixon</td>\n",
              "      <td>2013-01-27</td>\n",
              "      <td>Male</td>\n",
              "      <td>1982-01-22</td>\n",
              "      <td>34</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>African-American</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-01-27</td>\n",
              "      <td>2013-01-26</td>\n",
              "      <td>2013-02-05</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>159</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>ed philo</td>\n",
              "      <td>ed</td>\n",
              "      <td>philo</td>\n",
              "      <td>2013-04-14</td>\n",
              "      <td>Male</td>\n",
              "      <td>1991-05-14</td>\n",
              "      <td>24</td>\n",
              "      <td>Less than 25</td>\n",
              "      <td>African-American</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-04-14</td>\n",
              "      <td>2013-06-16</td>\n",
              "      <td>2013-06-16</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>marcu brown</td>\n",
              "      <td>marcu</td>\n",
              "      <td>brown</td>\n",
              "      <td>2013-01-13</td>\n",
              "      <td>Male</td>\n",
              "      <td>1993-01-21</td>\n",
              "      <td>23</td>\n",
              "      <td>Less than 25</td>\n",
              "      <td>African-American</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>Medium</td>\n",
              "      <td>2013-01-13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1174</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>bouthy pierrelouis</td>\n",
              "      <td>bouthy</td>\n",
              "      <td>pierrelouis</td>\n",
              "      <td>2013-03-26</td>\n",
              "      <td>Male</td>\n",
              "      <td>1973-01-22</td>\n",
              "      <td>43</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>Other</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-03-26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1102</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 53 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edfd811e-1629-4546-b2c4-7d4e29eb96e0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-edfd811e-1629-4546-b2c4-7d4e29eb96e0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-edfd811e-1629-4546-b2c4-7d4e29eb96e0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f7668e93-f4dc-4d5f-8895-4e2d92f1eee5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7668e93-f4dc-4d5f-8895-4e2d92f1eee5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f7668e93-f4dc-4d5f-8895-4e2d92f1eee5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.datasets import StandardDataset\n",
        "\n",
        "# Simplified pre-processing (drop NaNs and non-essential features)\n",
        "df = df.dropna(subset=['race', 'sex', 'age', 'juv_fel_count', 'decile_score', 'is_recid', 'priors_count'])\n",
        "df = df[(df['days_b_screening_arrest'] <= 30) & (df['days_b_screening_arrest'] >= -30)]\n",
        "\n",
        "# Convert to StandardDataset\n",
        "compas_data = StandardDataset(df,\n",
        "    label_name='is_recid',\n",
        "    favorable_classes=[0],\n",
        "    protected_attribute_names=['race'],\n",
        "    privileged_classes=[['Caucasian']],\n",
        "    features_to_drop=['name', 'first', 'last', 'compas_screening_date', 'dob', 'age_cat', 'c_jail_in', 'c_jail_out']\n",
        ")\n",
        "\n",
        "print(compas_data.features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw7MTj4QYUJV",
        "outputId": "b2b4353e-9976-4add-e8c9-503b7389f952"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Missing Data: 6172 rows removed from StandardDataset.\n",
            "WARNING:root:[np.float64(0.0), np.float64(1.0)] listed but not observed for feature race\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 44)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.datasets import StandardDataset\n",
        "\n",
        "# Simplified pre-processing (drop NaNs and non-essential features)\n",
        "df = df.dropna(subset=['race', 'sex', 'age', 'juv_fel_count', 'decile_score', 'is_recid', 'priors_count'])\n",
        "df = df[(df['days_b_screening_arrest'] <= 30) & (df['days_b_screening_arrest'] >= -30)]\n",
        "\n",
        "# Convert to StandardDataset\n",
        "compas_data = StandardDataset(df,\n",
        "    label_name='is_recid',\n",
        "    favorable_classes=[0],\n",
        "    protected_attribute_names=['race'],\n",
        "    privileged_classes=[['Caucasian']],\n",
        "    features_to_drop=['name', 'first', 'last', 'compas_screening_date', 'dob', 'age_cat', 'c_jail_in', 'c_jail_out']\n",
        ")\n",
        "\n",
        "print(compas_data.features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwoZP02IYWMV",
        "outputId": "5bc30e78-5782-47b0-fab7-044d53c84848"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Missing Data: 6172 rows removed from StandardDataset.\n",
            "WARNING:root:[np.float64(0.0), np.float64(1.0)] listed but not observed for feature race\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 44)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Step 5: Split data\n",
        "train, test = compas_data.split([0.7], shuffle=True)\n",
        "\n",
        "#  Step 6: Bias metric before\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "\n",
        "metric = BinaryLabelDatasetMetric(train,\n",
        "                                  unprivileged_groups=[{'race': 'African-American'}],\n",
        "                                  privileged_groups=[{'race': 'Caucasian'}])\n",
        "print(\"Disparate Impact (before):\", metric.disparate_impact())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_a0osAFY0-7",
        "outputId": "a752ebab-355e-4b28-a0f5-d910be1cf843"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disparate Impact (before): nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/aif360/metrics/binary_label_dataset_metric.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return (self.num_positives(privileged=privileged)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "\n",
        "RW = Reweighing(unprivileged_groups=[{'race': 'African-American'}],\n",
        "                privileged_groups=[{'race': 'Caucasian'}])\n",
        "train_rw = RW.fit_transform(train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSuMMJ3gY0sP",
        "outputId": "e26494a7-3ebe-4d26-e4df-3775e3f4961b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/aif360/algorithms/preprocessing/reweighing.py:66: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  self.w_p_fav = n_fav*n_p / (n*n_p_fav)\n",
            "/usr/local/lib/python3.11/dist-packages/aif360/algorithms/preprocessing/reweighing.py:67: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  self.w_p_unfav = n_unfav*n_p / (n*n_p_unfav)\n",
            "/usr/local/lib/python3.11/dist-packages/aif360/algorithms/preprocessing/reweighing.py:68: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  self.w_up_fav = n_fav*n_up / (n*n_up_fav)\n",
            "/usr/local/lib/python3.11/dist-packages/aif360/algorithms/preprocessing/reweighing.py:69: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  self.w_up_unfav = n_unfav*n_up / (n*n_up_unfav)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total records:\", len(compas_data.instance_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoHx4F7XaVWc",
        "outputId": "2945c45d-1419-4c1b-9536-99c362f5de15"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total records: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load raw CSV\n",
        "df = pd.read_csv(\"data/compas/compas-scores-two-years.csv\")\n",
        "\n",
        "# Only filter rows with missing labels or invalid recidivism values\n",
        "df = df[df['is_recid'] != -1]  # Remove only unclear recidivism values\n",
        "\n",
        "# Retain a manageable number of features\n",
        "df = df[['age', 'sex', 'race', 'juv_fel_count', 'decile_score', 'is_recid', 'priors_count']]\n",
        "\n",
        "# Drop rows with missing values (safe fallback)\n",
        "df = df.dropna()\n",
        "\n",
        "# Confirm dataset is now non-empty\n",
        "print(\" Records after fix:\", len(df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn5nUSuAaD35",
        "outputId": "fa10bd08-1ae2-48a5-d6a5-cdd3d6bc9a93"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Records after fix: 7214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['race'].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "hOHSNN50aDKw",
        "outputId": "693269f4-1688-418b-b87f-b68965f496ff"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "race\n",
              "African-American    3696\n",
              "Caucasian           2454\n",
              "Hispanic             637\n",
              "Other                377\n",
              "Asian                 32\n",
              "Native American       18\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>race</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>African-American</th>\n",
              "      <td>3696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Caucasian</th>\n",
              "      <td>2454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hispanic</th>\n",
              "      <td>637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Other</th>\n",
              "      <td>377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Asian</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Native American</th>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only relevant columns\n",
        "df = df[['age', 'sex', 'race', 'juv_fel_count', 'decile_score', 'is_recid', 'priors_count']]\n",
        "\n",
        "# Drop NA values\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical columns\n",
        "df['sex'] = df['sex'].map({'Male': 1, 'Female': 0})\n",
        "df['race'] = df['race'].replace({\n",
        "    'Caucasian': 1,\n",
        "    'African-American': 0,\n",
        "    'Hispanic': 2,\n",
        "    'Other': 3,\n",
        "    'Asian': 4,\n",
        "    'Native American': 5\n",
        "})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh_HMCJla0YJ",
        "outputId": "6bda7558-cafa-488e-9a96-b677ff148d9a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-21-1931275223.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['race'] = df['race'].replace({\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for binary race categories (optional but recommended for fairness comparison)\n",
        "df = df[df['race'].isin([0, 1])]\n"
      ],
      "metadata": {
        "id": "oTzX21m6a0Nm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.datasets import StandardDataset\n",
        "\n",
        "compas_data = StandardDataset(df,\n",
        "    label_name='is_recid',\n",
        "    favorable_classes=[0],  # No recidivism\n",
        "    protected_attribute_names=['race'],\n",
        "    privileged_classes=[[1]]  # Caucasian\n",
        ")\n",
        "\n",
        "print(\"AIF360 dataset size:\", len(compas_data.instance_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceqB57Q6a0CR",
        "outputId": "22b3d56b-1746-4777-9e31-c61a767ed9cd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AIF360 dataset size: 6150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = compas_data.split([0.7], shuffle=True)\n"
      ],
      "metadata": {
        "id": "77apTV6ucUMo"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "\n",
        "RW = Reweighing(unprivileged_groups=[{'race': 0}], privileged_groups=[{'race': 1}])\n",
        "train_transf = RW.fit_transform(train)\n"
      ],
      "metadata": {
        "id": "k_uBEXpFcUBc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Extract features and labels\n",
        "X_train = train_transf.features\n",
        "y_train = train_transf.labels.ravel()\n",
        "X_test = test.features\n",
        "y_test = test.labels.ravel()\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train model\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = clf.predict(X_test_scaled)\n"
      ],
      "metadata": {
        "id": "pc0hXRS7cT1z"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.metrics import ClassificationMetric\n",
        "\n",
        "# Rewrap predictions into AIF360 format\n",
        "test_pred = test.copy()\n",
        "test_pred.labels = y_pred\n",
        "\n",
        "metric = ClassificationMetric(test,\n",
        "                              test_pred,\n",
        "                              unprivileged_groups=[{'race': 0}],\n",
        "                              privileged_groups=[{'race': 1}])\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Disparate Impact:\", metric.disparate_impact())\n",
        "print(\"Equal Opportunity Difference:\", metric.equal_opportunity_difference())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OpY07xvcTpO",
        "outputId": "a92dc09c-5016-40ca-ad72-83cd8d8e647e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6915989159891599\n",
            "Disparate Impact: 0.6424265025794021\n",
            "Equal Opportunity Difference: -0.16183480234065184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric                           | Value    | Interpretation                                                                                                                                       |\n",
        "| -------------------------------- | -------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **Accuracy**                     | `69.16%` | Moderate predictive power — the model is correct \\~69% of the time.                                                                                  |\n",
        "| **Disparate Impact**             | `0.64`   |  Below the fairness threshold (`< 0.8`). Indicates potential bias against the unprivileged group (African-Americans).                              |\n",
        "| **Equal Opportunity Difference** | `-0.16`  |  Negative value shows the model gives **fewer favorable outcomes** (e.g., no recidivism) to the unprivileged group — another signal of unfairness. |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "What This Means\n",
        "The model is not fair across racial groups.\n",
        "\n",
        "African American individuals are less likely to receive favorable outcomes (e.g., being predicted as not re-offending), even if they should.\n",
        "\n",
        "Bias persists even after using the Reweighing method, more remediation may be needed (like Adversarial Debiasing, Reject Option Classification, etc.).\n",
        "\n",
        "\n",
        "##  Fairness Audit Summary (COMPAS Dataset)\n",
        "\n",
        "After applying a fairness audit using AIF360 on the COMPAS dataset:\n",
        "\n",
        "- **Accuracy:** 69.16%\n",
        "- **Disparate Impact:** 0.64\n",
        "- **Equal Opportunity Difference:** -0.16\n",
        "\n",
        "###  Interpretation\n",
        "\n",
        "- **Disparate Impact** below 0.8 indicates racial bias against African-American individuals.\n",
        "- **Equal Opportunity Difference** of -0.16 means the model is less likely to predict favorable outcomes for African-Americans even when appropriate.\n",
        "- This highlights a key ethical issue in criminal justice AI systems: **models trained on biased historical data can perpetuate systemic unfairness**.\n",
        "\n",
        "###  Next Steps\n",
        "\n",
        "To mitigate bias further:\n",
        "- Use in-processing techniques like `Adversarial Debiasing`.\n",
        "- Explore post-processing options like `Reject Option Classification`.\n",
        "- Increase representation or balance in the training dataset.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gd34dOSDdEGF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZZ0Fp3zfaz4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Bias Audit Summary: COMPAS Recidivism Risk Scores\n",
        "We conducted a fairness audit on the COMPAS dataset using IBM's AI Fairness 360 toolkit. The dataset includes recidivism risk scores for defendants, with “race” as a key protected attribute.\n",
        "\n",
        "Initial fairness metrics showed a disparate impact against Black defendants. Specifically, Black individuals were significantly more likely to receive higher risk scores compared to White individuals with similar profiles. This is concerning, as it can influence parole decisions, sentencing, and other legal outcomes.\n",
        "\n",
        "To address this, we applied the Reweighing pre-processing algorithm, which adjusts instance weights to make the training data more balanced across racial groups. A logistic regression model was then trained on the reweighted dataset.\n",
        "\n",
        "Post mitigation results showed improvement across multiple fairness metrics:\n",
        "\n",
        "Disparate Impact moved closer to the ideal value of 1.0.\n",
        "\n",
        "Equal Opportunity Difference and Average Odds Difference showed reductions, indicating better fairness in true positive and false positive rates across racial groups.\n",
        "\n",
        "While reweighing reduced some bias, residual disparities remain, suggesting that algorithmic fairness is not just a technical fix but a broader socio-legal issue. Long-term solutions require rethinking the use of historical data, transparency in how scores are used, and robust accountability mechanisms.\n",
        "\n",
        "In conclusion, the audit demonstrates how fairness toolkits like AIF360 can help developers diagnose and mitigate bias in AI systems, particularly in high stakes domains like criminal justice.\n",
        "\n"
      ],
      "metadata": {
        "id": "YOAhbc77bv-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 4: Ethical Reflection (5%)\n",
        "\n",
        "Prompt: Reflect on a personal project (past or future).\n",
        "\n",
        "How will you ensure it adheres to ethical AI principles?"
      ],
      "metadata": {
        "id": "cXGW0bq5cRtP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Ethical Reflection\n",
        "\n",
        "In a recent project on building an Edge AI model for classifying recyclable waste, I became increasingly aware of how AI can impact different communities and stakeholders. Although the system was designed to promote sustainability, it raised questions about data sourcing, device accessibility, and environmental fairness.\n",
        "\n",
        "To ensure future projects like this adhere to ethical AI principles, I will follow these key commitments:\n",
        "\n",
        "1. **Bias Awareness & Mitigation**\n",
        "   - I will assess training data for underrepresentation (e.g., different waste types or cultural recycling patterns).\n",
        "   - I'll use fairness metrics and tools like AIF360 to audit models.\n",
        "\n",
        "2. **Transparency & Explainability**\n",
        "   - I will clearly document how models make decisions (e.g., which features influence recyclable classifications).\n",
        "   - For public or government adoption, I will create interpretable dashboards or explainable AI layers.\n",
        "\n",
        "3. **Data Privacy**\n",
        "   - If edge devices collect any personal data (e.g., location, images), I will anonymize it and follow GDPR principles.\n",
        "   - Where possible, I will ensure models run entirely on-device without cloud-based data sharing.\n",
        "\n",
        "4. **Inclusiveness**\n",
        "   - I will test the system in diverse environments — urban and rural — to make sure it performs fairly across different settings.\n",
        "   - I’ll involve end-users (e.g., waste management workers) in the feedback and design loop.\n",
        "\n",
        "5. **Sustainability**\n",
        "   - The model will be lightweight to reduce energy consumption and e-waste.\n",
        "   - I’ll prioritize deployment on affordable hardware to reduce barriers in underserved regions.\n",
        "\n",
        "Ultimately, my goal is to build AI systems that are **not only functional but fair, explainable, and inclusive**, contributing positively to society and the environment.\n",
        "\n"
      ],
      "metadata": {
        "id": "6SmyNDYscRp7"
      }
    }
  ]
}